{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook downloads and generates data for neural network ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 649,
     "status": "ok",
     "timestamp": 1624736186857,
     "user": {
      "displayName": "Abhishek Gautam",
      "photoUrl": "",
      "userId": "08238433215313575336"
     },
     "user_tz": -330
    },
    "id": "LH0Y-76gewdf"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np # linear algebra\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm,trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1624736247966,
     "user": {
      "displayName": "Abhishek Gautam",
      "photoUrl": "",
      "userId": "08238433215313575336"
     },
     "user_tz": -330
    },
    "id": "2AFylwtte625"
   },
   "outputs": [],
   "source": [
    "def gnss_log_to_dataframes(path):\n",
    "    print('Loading ' + path, flush=True)\n",
    "    gnss_section_names = {'Raw','UncalAccel', 'UncalGyro', 'UncalMag', 'Status'} # 'Fix', 'OrientationDeg' -->empty\n",
    "    with open(path) as f_open:\n",
    "        datalines = f_open.readlines()\n",
    "\n",
    "    datas = {k: [] for k in gnss_section_names}\n",
    "    gnss_map = {k: [] for k in gnss_section_names}\n",
    "    for dataline in datalines:\n",
    "        is_header = dataline.startswith('#')\n",
    "        dataline = dataline.strip('#').strip().split(',')\n",
    "        # skip over notes, version numbers, etc\n",
    "        if is_header and dataline[0] in gnss_section_names:\n",
    "            gnss_map[dataline[0]] = dataline[1:]\n",
    "        elif not is_header:\n",
    "            datas[dataline[0]].append(dataline[1:])\n",
    "\n",
    "    results = dict()\n",
    "    for k, v in datas.items():\n",
    "        results[k] = pd.DataFrame(v, columns=gnss_map[k])\n",
    "    # pandas doesn't properly infer types from these lists by default\n",
    "    for k, df in results.items():\n",
    "        for col in df.columns:\n",
    "            if col == 'CodeType':\n",
    "                continue\n",
    "            results[k][col] = pd.to_numeric(results[k][col])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rawdf(log_file):\n",
    "    df_collection=gnss_log_to_dataframes(log_file)\n",
    "    # load raw df\n",
    "    df_raw=df_collection['Raw']\n",
    "    df_raw=df_raw[['utcTimeMillis','TimeNanos','FullBiasNanos']]\n",
    "    gpstime=round((df_raw['TimeNanos']-df_raw['FullBiasNanos'])/1000000.0).astype('Int64')\n",
    "    df_raw.insert(1,'millisSinceGpsEpoch',gpstime)\n",
    "    df_raw=df_raw.drop_duplicates(subset='utcTimeMillis',ignore_index=True)\n",
    "    df_raw.drop(labels=['TimeNanos','FullBiasNanos'],axis=1,inplace=True)\n",
    "    # load accel df\n",
    "    acc_df=df_collection['UncalAccel']\n",
    "    acc_df.drop(labels='elapsedRealtimeNanos',axis=1,inplace=True)\n",
    "    df_raw=df_raw.merge(acc_df,how='outer',on='utcTimeMillis')\n",
    "    # load gyro\n",
    "    gyro_df=df_collection['UncalGyro']\n",
    "    gyro_df.drop(labels='elapsedRealtimeNanos',axis=1,inplace=True)\n",
    "    df_raw=df_raw.merge(gyro_df,how='outer',on='utcTimeMillis')\n",
    "    # load mag df\n",
    "    mag_df=df_collection['UncalMag']\n",
    "    mag_df.drop(labels='elapsedRealtimeNanos',axis=1,inplace=True)\n",
    "    df_raw=df_raw.merge(mag_df,how='outer',on='utcTimeMillis')\n",
    "    \n",
    "    df_raw.sort_values(by=['utcTimeMillis'],inplace=True,ignore_index=True)\n",
    "    return df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_avail(l,index):\n",
    "    pos=index+1\n",
    "    while (np.isnan(l[pos])):\n",
    "        pos+=1\n",
    "    return pos\n",
    "\n",
    "def last_avail(l,index):\n",
    "    pos=index-1\n",
    "    while (np.isnan(l[pos])):\n",
    "        pos-=1\n",
    "    return pos\n",
    "\n",
    "def populate_numpy(l):\n",
    "    \n",
    "    if(np.isnan(l[0,1])): # 0 pos population\n",
    "        pos=next_avail(l[:,1],0)\n",
    "        l[0,1:]=l[pos,1:]\n",
    "    k=l.shape[0]\n",
    "    \n",
    "    if(np.isnan(l[k-1,1])): #last pos population\n",
    "        pos=last_avail(l[:,1],k-1)\n",
    "        l[k-1,1:]=l[pos,1:]\n",
    "    \n",
    "    for i in trange(k):\n",
    "        if (np.isnan(l[i,1])):\n",
    "            if (i==k-1):\n",
    "                l[i,1:]=l[i-1,1:]\n",
    "            else:\n",
    "                pos=next_avail(l[:,1],i)\n",
    "            # weighted time averaged nan assignment\n",
    "                r1=l[i,0]-l[i-1,0]\n",
    "                r2=l[pos,0]-l[i,0]\n",
    "                l[i,1:]=((l[i-1,1:]*r2)+(l[pos,1:]*r1))/(r1+r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_gdim(l):\n",
    "    pos=0\n",
    "    if(np.isnan(l[0,1])):\n",
    "        pos=next_avail(l[:,1],0)\n",
    "    if(l[pos,-1]>9.5): # by default if z-dim is g then return array as it is\n",
    "        return l\n",
    "    elif(l[pos,-2]>9.5): # if y-dim is g swap y and z dims\n",
    "        l[:,[-2,-1]]=l[:,[-1,-2]]\n",
    "        return l\n",
    "    elif(l[pos,-3]>9.5):\n",
    "        l[:,[-3,-1]]=l[:,[-1,-3]]\n",
    "        return l\n",
    "    else:\n",
    "        l[:,[-2,-1]]=l[:,[-1,-2]]\n",
    "        return l\n",
    "\n",
    "def populator(df):\n",
    "    l=df[['utcTimeMillis','UncalAccelXMps2','UncalAccelYMps2','UncalAccelZMps2']].to_numpy()\n",
    "    l=correct_gdim(l)\n",
    "    populate_numpy(l)\n",
    "    df=df.assign(UncalAccelXMps2=l[:,1],UncalAccelYMps2=l[:,2],UncalAccelZMps2=l[:,3])\n",
    "    \n",
    "    l=df[['utcTimeMillis','UncalGyroXRadPerSec','UncalGyroYRadPerSec','UncalGyroZRadPerSec']].to_numpy()\n",
    "    populate_numpy(l)\n",
    "    df=df.assign(UncalGyroXRadPerSec=l[:,1],UncalGyroYRadPerSec=l[:,2],UncalGyroZRadPerSec=l[:,3])\n",
    "    \n",
    "    l=df[['utcTimeMillis','UncalMagXMicroT','UncalMagYMicroT','UncalMagZMicroT']].to_numpy()\n",
    "    populate_numpy(l)\n",
    "    df=df.assign(UncalMagXMicroT=l[:,1],UncalMagYMicroT=l[:,2],UncalMagZMicroT=l[:,3])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_main_df(log_file):\n",
    "    df=gen_rawdf(log_file)\n",
    "    df=populator(df)\n",
    "    l=df[['utcTimeMillis']].to_numpy()\n",
    "    temp=np.zeros(l.shape,dtype=np.float64)\n",
    "    for i in range(l.shape[0]):\n",
    "        if i==l.shape[0]-1:\n",
    "            temp[i]=temp[i-1]\n",
    "        else :\n",
    "            temp[i]=l[i+1]-l[i]\n",
    "    df.insert(11,'delta_t',temp)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(df,gt_df):\n",
    "    h=df[df['millisSinceGpsEpoch'].notna()].index.values\n",
    "    k=gt_df.index.stop-2\n",
    "    dataset=np.zeros((k,),dtype=dict)\n",
    "    for i in trange(k):\n",
    "        data=df.iloc[h[i]:h[i+1]+1].to_numpy()\n",
    "        acc=data[:,2:5].astype(np.float64)\n",
    "        gyr=data[:,5:8].astype(np.float64)\n",
    "        mag=data[:,8:11].astype(np.float64)\n",
    "        delta_t=data[:,11].astype(np.float64)\n",
    "        lat=np.float64(data[0,12])\n",
    "        lon=np.float64(data[0,13])\n",
    "        gt=gt_df.iloc[i+1,3:5].to_numpy()\n",
    "        gt_lat=np.float64(gt[0])\n",
    "        gt_lon=np.float64(gt[1])\n",
    "        dataset[i]={'readings':[acc,gyr,mag,delta_t,lat,lon],'ground_truth':[gt_lat,gt_lon]}\n",
    "    dataset[0]['q0']=np.array([df.iloc[h[0]-1,2:5].to_numpy().astype(np.float64),df.iloc[h[0]-1,8:11].to_numpy().astype(np.float64)])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df=pd.read_csv('data/baseline_locations_train.csv')\n",
    "phones=baseline_df.phone.unique()\n",
    "baseline_df=baseline_df.astype({'millisSinceGpsEpoch':'Int64'})\n",
    "baseline_df.drop(labels=['collectionName','phoneName','heightAboveWgs84EllipsoidM'],axis=1,inplace=True)\n",
    "for i in phones:\n",
    "    folder=\"data/train/\"+i.replace('_','/')\n",
    "    log_file=folder+'/'+folder.split('/')[-1]+'_GnssLog.txt'\n",
    "    gt_file=folder+'/ground_truth.csv'\n",
    "    main_df=gen_main_df(log_file) # csv with all raw data for accelerometer gyro and mag [ Delta_t should be added here]\n",
    "    main_df=main_df.merge(baseline_df,how='left',on='millisSinceGpsEpoch') #merge baseline\n",
    "    gt_df=pd.read_csv(gt_file)\n",
    "    dataset=gen_dataset(main_df,gt_df)\n",
    "    np.save('decimeter/train/'+i+'.npy',dataset)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOjpGfgPBffvTGc2kCZX8RQ",
   "collapsed_sections": [],
   "name": "decimeter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
